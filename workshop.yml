---
AWSTemplateFormatVersion: '2010-09-09'

Description: CFN template for spinning up environment for MLOps workshop.

Metadata: 
  AWS::CloudFormation::Interface: 
    ParameterGroups: 
      - 
        Label: 
          default: "Notebook Configuration"
        Parameters: 
          - NotebookName
          - NotebookInstanceType
          - VolumeSize

Parameters:

  NotebookName:
    Type: String
    Default: mlops-workshop
    Description: Enter the name of the SageMaker notebook instance.

  GitHubUser:
    Default: tom5610
    Type: String
    Description: Your GitHub username 

  GitHubRepo:
    Default: amazon-sagemaker-mlops-workshop
    Type: String
    Description: Name of the GitHub repository

  GitHubBranch:
    Default: main
    Type: String
    Description: Name of the branch the code is located

  GitHubToken: 
    Default: ""
    NoEcho: true
    Type: String
    Description: GitHub OAuthToken with access to Repo. Go to https://github.com/settings/tokens for reference

  ModelName:
    Default: directmarketing
    Type: String
    Description: Model name

  VolumeSize:
    Type: Number
    Default: 10
    MinValue: 5
    MaxValue: 16384
    ConstraintDescription: Must be an integer between 5 (GB) and 16384 (16 TB).
    Description: Enter the size of the EBS volume in GB.

  NotebookInstanceType:
    Type: String
    Default: ml.t2.medium
    Description: Enter the SageMaker notebook instance type. 

  RequireModelTraining:
    Type: String
    Default: true
    Description: Define whether the pipeline does model training by default.
    AllowedValues: [true, false]

  RequireHPO:
    Type: String
    Default: false
    Description: Define whether the pipeline does Hyperparameters Optimization by default.
    AllowedValues: [true, false]

  NotificationEmailId:
    Type: String
    Default: tomlu@amazon.com
    Description: Define the email id to receive model training notification.

  ModelTrainingNotificationTopicName:
    Type: String
    Default: ml-pipeline-notification-topic
    Description: The model training notification topic name.

Conditions:
  GitHubTokenEmpty: !Equals [!Ref GitHubToken, ""]

Resources:
  # SageMaker Execution Role
  SageMakerRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service: sagemaker.amazonaws.com
            Action: sts:AssumeRole
          - Effect: Allow 
            Principal:
              Service: events.amazonaws.com
            Action: sts:AssumeRole
          - Effect: Allow 
            Principal:
              Service: codebuild.amazonaws.com
            Action: sts:AssumeRole
          - Effect: Allow 
            Principal:
              Service: states.amazonaws.com
            Action: sts:AssumeRole
          - Effect: Allow 
            Principal:
              Service: lambda.amazonaws.com
            Action: sts:AssumeRole
      Path: "/"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/AmazonSageMakerFullAccess"
        - "arn:aws:iam::aws:policy/AmazonS3FullAccess"
        - "arn:aws:iam::aws:policy/AmazonAthenaFullAccess"
        - "arn:aws:iam::aws:policy/AWSStepFunctionsFullAccess"
        - "arn:aws:iam::aws:policy/IAMFullAccess"
        - "arn:aws:iam::aws:policy/AmazonSNSFullAccess"
        - "arn:aws:iam::aws:policy/AWSCloudTrailFullAccess"
        - "arn:aws:iam::aws:policy/AWSLambdaFullAccess"        
      Policies:
        - PolicyName: CodeBuildAccessPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Sid: EventAccess
              Effect: Allow
              Action:
                - ssm:GetParameter
                - ssm:GetParameters
              Resource:
                - arn:aws:ssm:*:*:parameter/CodeBuild/*
                - arn:aws:ssm:*:*:parameter/ml_pipeline/*
  PipelineRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub mlops-${ModelName}-pipeline-role
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service: "codepipeline.amazonaws.com"
            Action: "sts:AssumeRole"
      Path: "/"
      Policies:
        - PolicyName: "mlops-pipeline"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Sid: CloudFormation
                Effect: Allow
                Action:
                  - cloudformation:*
                  - lambda:AddPermission
                  - lambda:CreateFunction
                  - lambda:DeleteFunction
                  - lambda:InvokeFunction
                Resource: "*"
              - Sid: CodeBuild
                Effect: Allow
                Action:
                  - codebuild:BatchGetBuilds
                  - codebuild:StartBuild
                Resource: "*"
              - Sid: AllowPassRoleCloudFormation
                Effect: Allow
                Action:
                  - iam:PassRole
                Resource: !GetAtt MLOpsRole.Arn
              - Sid: StepFunctionsExecution
                Effect: Allow
                Action:
                  - states:*
                Resource: "*"

  MLOpsRole:
    Type: "AWS::IAM::Role"
    Properties:
      RoleName: !Sub mlops-${ModelName}-deploy-role
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: "Allow"
            Principal:
              Service:
                - "sagemaker.amazonaws.com"
            Action:
              - "sts:AssumeRole"
          - Effect: "Allow"
            Principal:
              Service:
                - "cloudformation.amazonaws.com"
            Action:
              - "sts:AssumeRole"
      Path: "/"
      Policies:
        - PolicyName: "mlops-deploy"
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Sid: CloudFormation
                Effect: Allow
                Action:
                  - cloudformation:*
                  - iam:AttachRolePolicy
                  - iam:CreateRole
                  - iam:CreatePolicy
                  - iam:GetRole
                  - iam:GetRolePolicy
                  - iam:DeleteRole
                  - iam:DetachRolePolicy
                  - iam:PutRolePolicy
                  - iam:PassRole
                  - iam:DeleteRolePolicy
                  - iam:CreateServiceLinkedRole
                  - lambda:InvokeFunction
                Resource: "*"
              - Sid: SageMakerDeployment
                Effect: Allow
                Action:
                  - sagemaker:CreateEndpoint
                  - sagemaker:CreateEndpointConfig
                  - sagemaker:CreateModel
                  - sagemaker:DeleteEndpoint
                  - sagemaker:DeleteEndpointConfig
                  - sagemaker:DeleteModel
                  - sagemaker:DescribeEndpoint
                  - sagemaker:DescribeEndpointConfig
                  - sagemaker:DescribeModel
                  - sagemaker:UpdateEndpointWeightsAndCapacities
                  - kms:CreateGrant
                Resource: "*"
              - Sid: ApiDeployment
                Effect: Allow
                Action:
                  - apigateway:*
                  - application-autoscaling:DeregisterScalableTarget
                  - application-autoscaling:DeleteScalingPolicy
                  - application-autoscaling:DescribeScalingPolicies
                  - application-autoscaling:PutScalingPolicy
                  - application-autoscaling:DescribeScalingPolicies
                  - application-autoscaling:RegisterScalableTarget
                  - application-autoscaling:DescribeScalableTargets
                  - cloudwatch:DeleteAlarms
                  - cloudwatch:DescribeAlarms
                  - cloudwatch:PutMetricAlarm
                  - codedeploy:*
                  - lambda:AddPermission
                  - lambda:CreateAlias
                  - lambda:CreateFunction
                  - lambda:DeleteAlias
                  - lambda:DeleteFunction
                  - lambda:GetFunction
                  - lambda:GetAlias
                  - lambda:ListTags
                  - lambda:ListVersionsByFunction
                  - lambda:PublishVersion
                  - lambda:RemovePermission
                  - lambda:UpdateFunctionCode
                  - lambda:UpdateFunctionConfiguration
                  - sns:CreateTopic
                  - sns:DeleteTopic
                  - sns:GetTopicAttributes
                  - sns:ListTopics
                Resource: "*"
              - Sid: AllowPassRoleSageMaker
                Effect: Allow
                Action:
                  - iam:PassRole
                Resource: "*"
                Condition:
                  StringEquals:
                    iam:PassedToService: sagemaker.amazonaws.com

  S3Policy:
    Type: AWS::IAM::Policy
    Properties:
      PolicyName: !Sub mlops-${ModelName}-s3-policy
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Sid: S3Resources
            Effect: Allow
            Action:
              - s3:CreateBucket
              - s3:GetBucket*
              - s3:GetObject*
              - s3:ListBucket
              - s3:PutObject
            Resource:
              - !Sub arn:aws:s3:::${ArtifactBucket}/*
              - !Sub arn:aws:s3:::${ArtifactBucket}
              - !Sub arn:aws:s3:::sagemaker-${AWS::Region}-${AWS::AccountId}/*
              - !Sub arn:aws:s3:::sagemaker-${AWS::Region}-${AWS::AccountId}
          - Sid: AllowLogs
            Effect: Allow
            Action:
              - logs:CreateLogGroup
              - logs:CreateLogStream
              - logs:PutLogEvents
            Resource: "*"
      Roles:
        - !Ref SageMakerRole
        - !Ref PipelineRole
        - !Ref MLOpsRole

  StepFunctionsWorkflowExecutionRole:
    Type: "AWS::IAM::Role"
    Properties:
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          -
            Effect: Allow
            Principal:
              Service: states.amazonaws.com
            Action: sts:AssumeRole
      Path: "/"
      ManagedPolicyArns:
        - "arn:aws:iam::aws:policy/service-role/AWSLambdaRole"
        - "arn:aws:iam::aws:policy/CloudWatchEventsFullAccess"
      Policies:
        - PolicyName: StepFunctionsWorkflowExecutionPolicy
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
            - Sid: EventAccess
              Effect: Allow
              Action:
                - events:PutTargets
                - events:DescribeRule
                - events:PutRule
              Resource:
                - arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTrainingJobsRule
                - arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTransformJobsRule
                - arn:aws:events:*:*:rule/StepFunctionsGetEventsForSageMakerTuningJobsRule
                - arn:aws:events:*:*:rule/StepFunctionsGetEventsForECSTaskRule
                - arn:aws:events:*:*:rule/StepFunctionsGetEventsForBatchJobsRule
            - Sid: PassRole
              Effect: Allow
              Action: iam:PassRole
              Resource:
                - !GetAtt "SageMakerRole.Arn"
              Condition:
                StringEquals:
                  iam:PassedToService: sagemaker.amazonaws.com
            - Sid: GeneralAccess
              Effect: Allow
              Action:
                - batch:DescribeJobs
                - batch:SubmitJob
                - batch:TerminateJob
                - dynamodb:DeleteItem
                - dynamodb:GetItem
                - dynamodb:PutItem
                - dynamodb:UpdateItem
                - ecs:DescribeTasks
                - ecs:RunTask
                - ecs:StopTask
                - glue:BatchStopJobRun
                - glue:GetJobRun
                - glue:GetJobRuns
                - glue:StartJobRun
                - lambda:InvokeFunction
                - sagemaker:CreateEndpoint
                - sagemaker:CreateEndpointConfig
                - sagemaker:CreateHyperParameterTuningJob
                - sagemaker:CreateModel
                - sagemaker:CreateProcessingJob
                - sagemaker:CreateTrainingJob
                - sagemaker:CreateTransformJob
                - sagemaker:DeleteEndpoint
                - sagemaker:DeleteEndpointConfig
                - sagemaker:DescribeHyperParameterTuningJob
                - sagemaker:DescribeProcessingJob
                - sagemaker:DescribeTrainingJob
                - sagemaker:DescribeTransformJob
                - sagemaker:ListProcessingJobs
                - sagemaker:ListTags
                - sagemaker:StopHyperParameterTuningJob
                - sagemaker:StopProcessingJob
                - sagemaker:StopTrainingJob
                - sagemaker:StopTransformJob
                - sagemaker:UpdateEndpoint
                - sns:Publish
                - sqs:SendMessage
              Resource: "*"

  CodeCommitPolicy:
    Type: AWS::IAM::Policy
    Condition: GitHubTokenEmpty
    Properties:
      PolicyName: !Sub mlops-${ModelName}-codecommit-policy
      PolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Sid: AlowCodeCommit
            Effect: Allow
            Action:
              - codecommit:*
            Resource: !GetAtt CodeCommitRepository.Arn
      Roles:
        - !Ref SageMakerRole
        - !Ref PipelineRole

  # SageMaker lifecycle
  NotebookLifecycle:
    Type: "AWS::SageMaker::NotebookInstanceLifecycleConfig"
    Properties: 
      NotebookInstanceLifecycleConfigName: !Sub ${ModelName}-lifecycle-config
      OnCreate:
        - Content:
            Fn::If:
              - GitHubTokenEmpty
              - Fn::Base64:
                  Fn::Sub: |
                    #!/bin/bash
                    # Clone the public github repo, and push it to a local codecommit branch
                    export HOME=/root/
                    echo "Configuring github for AWS credentials"
                    git config --global credential.helper '!aws codecommit credential-helper $@'
                    git config --global credential.UseHttpPath true
                    cp /root/.gitconfig /home/ec2-user/ && chown ec2-user:ec2-user /home/ec2-user/.gitconfig
                    echo "Clone the public repo and push it to codecommit repo"
                    git clone -b ${GitHubBranch} "https://github.com/${GitHubUser}/${GitHubRepo}.git" /tmp/${GitHubRepo}
                    cd /tmp/${GitHubRepo}
                    git remote add codecommit ${CodeCommitRepository.CloneUrlHttp}
                    git push --set-upstream codecommit ${GitHubBranch}
              - Ref: AWS::NoValue
      OnStart:
        - Content:
            Fn::Base64:
              Fn::Sub: |
                #!/bin/bash
                touch /etc/profile.d/jupyter-env.sh
                echo "export ARTIFACT_BUCKET=${ArtifactBucket}" >> /etc/profile.d/jupyter-env.sh
                echo "export PIPELINE_NAME=${ModelName}" >> /etc/profile.d/jupyter-env.sh
                echo "export MODEL_NAME=${ModelName}" >> /etc/profile.d/jupyter-env.sh

  # SageMaker notebook
  NotebookInstance:
    Type: "AWS::SageMaker::NotebookInstance"
    Properties:
      InstanceType: !Ref NotebookInstanceType
      NotebookInstanceName: !Ref NotebookName
      RoleArn: !GetAtt SageMakerRole.Arn
      VolumeSizeInGB: !Ref VolumeSize
      DefaultCodeRepository: !GetAtt SageMakerCodeRepository.CodeRepositoryName
      LifecycleConfigName: !GetAtt NotebookLifecycle.NotebookInstanceLifecycleConfigName
 
  S3Bucket:
    Type: AWS::S3::Bucket
    DeletionPolicy: Delete
    Properties:
      BucketName: !Sub '${ModelName}-${AWS::Region}-${AWS::AccountId}'
      
  GitHubSecret:
    Type: AWS::SecretsManager::Secret
    Properties:
      Description: !Sub GitHub Secret for ${GitHubRepo}
      SecretString: !Sub '{"username":"${GitHubUser}", "password":"${GitHubToken}"}'
  
  CodeCommitRepository:
    Type: AWS::CodeCommit::Repository
    Condition: GitHubTokenEmpty
    Properties:
      RepositoryName: !Ref GitHubRepo
      RepositoryDescription: !Sub SageMaker safe deployment pipeline for ${ModelName}

  SageMakerCodeRepository:
    Type: AWS::SageMaker::CodeRepository 
    Properties:
      CodeRepositoryName: !Join [ "-",  !Split [ "_" , !Ref GitHubRepo ] ]
      GitConfig:
        RepositoryUrl:
          Fn::If:
            - GitHubTokenEmpty
            - !GetAtt CodeCommitRepository.CloneUrlHttp
            - !Sub https://github.com/${GitHubUser}/${GitHubRepo}.git
        Branch: !Ref GitHubBranch
        SecretArn:
          Fn::If:
            - GitHubTokenEmpty
            - !Ref "AWS::NoValue"
            - !Ref GitHubSecret

  BuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: !Sub ${ModelName}-build
      Description: Builds the assets required for executing the rest of pipeline
      ServiceRole: !GetAtt SageMakerRole.Arn
      Artifacts:
        Type: CODEPIPELINE 
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/amazonlinux2-x86_64-standard:3.0
        PrivilegedMode: true
      Source:
        Type: CODEPIPELINE
        BuildSpec: notebook/pipeline/buildspec.yml
      TimeoutInMinutes: 10

  ProductionDeploymentBuildProject:
    Type: AWS::CodeBuild::Project
    Properties:
      Name: !Sub ${ModelName}-deployment-pipeline-build
      Description: Builds the assets required for executing production deployment pipeline
      ServiceRole: !GetAtt SageMakerRole.Arn
      Artifacts:
        Type: CODEPIPELINE 
      Environment:
        Type: LINUX_CONTAINER
        ComputeType: BUILD_GENERAL1_SMALL
        Image: aws/codebuild/amazonlinux2-x86_64-standard:3.0
        PrivilegedMode: true
      Source:
        Type: CODEPIPELINE
        BuildSpec: notebook/pipeline/prod_buildspec.yml
      TimeoutInMinutes: 10

  DeployPipeline:
    Type: "AWS::CodePipeline::Pipeline"
    Properties:
      Name: !Sub ${ModelName}
      RoleArn: !GetAtt PipelineRole.Arn
      ArtifactStore:
        Type: S3
        Location: !Ref ArtifactBucket
      Stages:
        - Name: Source
          Actions:
            - Fn::If:
              - GitHubTokenEmpty
              - Name: GitSource
                ActionTypeId:
                  Category: Source
                  Owner: AWS
                  Version: "1"
                  Provider: CodeCommit
                Configuration:
                  RepositoryName: !Ref GitHubRepo
                  BranchName: !Ref GitHubBranch
                OutputArtifacts:
                  - Name: ModelSourceOutput
              - Name: GitSource
                ActionTypeId:
                  Category: Source
                  Owner: ThirdParty
                  Version: "1"
                  Provider: GitHub
                OutputArtifacts:
                  - Name: ModelSourceOutput
                Configuration:
                  Owner: !Ref GitHubUser
                  Repo: !Ref GitHubRepo
                  Branch: !Ref GitHubBranch
                  OAuthToken: !Ref GitHubToken
            - Name: DataSource
              ActionTypeId:
                Category: Source
                Owner: AWS
                Version: "1"
                Provider: S3
              OutputArtifacts:
                - Name: DataSourceOutput
              Configuration:
                S3Bucket: !Ref ArtifactBucket
                S3ObjectKey: !Sub ${ModelName}/data-source.zip
              RunOrder: 1                  
        - Name: DevModelTraining
          Actions:
            - Name: SetupMLPipeline
              InputArtifacts:
                - Name: ModelSourceOutput
                - Name: DataSourceOutput
              OutputArtifacts:
                - Name: PipelineBuildOutput
              ActionTypeId:
                Category: Build
                Owner: AWS
                Version: "1"
                Provider: CodeBuild
              Configuration:
                ProjectName: !Ref BuildProject
                PrimarySource: ModelSourceOutput
              RunOrder: 1
            - Name: ExecutePipeline
              InputArtifacts:
                - Name: PipelineBuildOutput
              OutputArtifacts:
                - Name: PipelineExecutionOutput
              ActionTypeId:
                Category: Invoke
                Owner: AWS
                Version: "1"
                Provider: StepFunctions
              Configuration:
                StateMachineArn: !Sub "arn:aws:states:${AWS::Region}:${AWS::AccountId}:stateMachine:${ModelName}-dev-model-training-pipeline"
                InputType: FilePath
                Input: PipelineBuildOutput::input.json
              RunOrder: 2
        - Name: ApproveProductionDeployment
          Actions:
            - Name: ApproveDeploy
              ActionTypeId:
                Category: Approval
                Owner: AWS
                Version: "1"
                Provider: Manual
              Configuration:
                CustomData: "Deploy Model to Production Environment? (Please check the evaluation report before doing so)"          
        - Name: ProductionDeployment
          Actions:
            - Name: CreateProductionDeploymentPipeline
              InputArtifacts:
                - Name: ModelSourceOutput
              OutputArtifacts:
                - Name: ProductionDeploymentBuildOutput
              ActionTypeId:
                Category: Build
                Owner: AWS
                Version: "1"
                Provider: CodeBuild
              Configuration:
                ProjectName: !Ref ProductionDeploymentBuildProject
                PrimarySource: ModelSourceOutput
              RunOrder: 1
            - Name: ExecuteProductionDeploymentPipeline
              InputArtifacts:
                - Name: ProductionDeploymentBuildOutput
              OutputArtifacts:
                - Name: ProductionDeploymentExecutionOutput
              ActionTypeId:
                Category: Invoke
                Owner: AWS
                Version: "1"
                Provider: StepFunctions
              Configuration:
                StateMachineArn: !Sub "arn:aws:states:${AWS::Region}:${AWS::AccountId}:stateMachine:${ModelName}-prod-deployment-pipeline"
                InputType: FilePath
                Input: ProductionDeploymentBuildOutput::prod_input.json
              RunOrder: 2

  ArtifactBucket:
    Type: AWS::S3::Bucket
    Properties:
      BucketName: !Sub mlops-${ModelName}-artifact-${AWS::Region}-${AWS::AccountId}
      AccessControl: Private
      VersioningConfiguration:
        Status: Enabled

  WorkflowExecutionRoleParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/workflow_execution_role
      Type: String
      Value: !GetAtt "StepFunctionsWorkflowExecutionRole.Arn"

  WorkflowNotificationTopicParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/workflow_notification_topic_name
      Type: String
      Value: !Ref ModelTrainingNotificationTopicName

  WorkflowNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/workflow_name
      Type: String
      Value: !Sub ${ModelName}-dev-model-training-pipeline

  ProdDeployWorkflowNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/prd_workflow_name
      Type: String
      Value: !Sub ${ModelName}-prod-deployment-pipeline

  RequireHPOParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/require_hpo
      Type: String
      Value: !Ref RequireHPO

  RequireModelTrainingParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/require_model_training
      Type: String
      Value: !Ref RequireModelTraining

  ModelTrainingS3BucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/model_training_s3_bucket_name
      Type: String
      Value: !Ref S3Bucket

  PipelineArtifactS3BucketNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/pipeline_artifact_s3_bucket_name
      Type: String
      Value: !Ref ArtifactBucket

  ModelTrainingNotificationTopic:
    Type: AWS::SNS::Topic
    Properties: 
      DisplayName: Model Training Notification Topic
      Subscription: 
        - Endpoint: !Ref NotificationEmailId
          Protocol: "email"
      TopicName: !Ref ModelTrainingNotificationTopicName


  QueryEndpointLambdaFunctionNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/query_endpoint
      Type: String
      Value: !Sub ${ModelName}_query_endpoint

  QueryHpoJobLambdaFunctionNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/query_hpo_job
      Type: String
      Value: !Sub ${ModelName}_query_hpo_job

  CreateBlueGreenEndpointConfigLambdaFunctionNameParameter:
    Type: AWS::SSM::Parameter
    Properties:
      Name: /ml_pipeline/create_blue_green_endpoint_config
      Type: String
      Value: !Sub ${ModelName}_create_blue_green_endpoint_config
    
      
  QueryEndpointLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub ${ModelName}_query_endpoint
      Handler: index.lambda_handler
      MemorySize: 128
      Role: !GetAtt SageMakerRole.Arn
      Runtime: python3.7
      Timeout: 15
      Code:
        ZipFile: |
          import boto3
          import logging
          import json

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          sm_client = boto3.client('sagemaker')

          #Retrieve endpoint existence and status info.
          def lambda_handler(event, context):

              if ('EndpointName' in event):
                  endpoint_name = event['EndpointName']
              else:
                  raise KeyError('EndpointName key not found in function input!'+
                                ' The input received was: {}.'.format(json.dumps(event)))

              #Query boto3 API to check Endpoint.
              endpoint_existed = False
              endpoint_status = None
              try:
                  response = sm_client.describe_endpoint(EndpointName = endpoint_name)
                  endpoint_existed = True
                  endpoint_status = response['EndpointStatus']
                  logger.info("Endpoint:{} has status:{}.".format(endpoint_name, endpoint_status))
              except Exception as e:
                  response = ('Failed to read endpoint info!'+ 
                              ' The endpoint may not exist or the endpoint name may be incorrect.'+ 
                              ' Check SageMaker to confirm the endpoint name.')
                  print(e)
                  print('{} Attempted to read endpoint name: {}.'.format(response, endpoint_name))

              return {
                  'statusCode': 200,
                  'endpoint_existed': endpoint_existed,
                  'endpoint_status': endpoint_status
              }

      Description: Query Endpoint information.

  QueryHpoJobLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub ${ModelName}_query_hpo_job
      Handler: index.lambda_handler
      MemorySize: 128
      Role: !GetAtt SageMakerRole.Arn
      Runtime: python3.7
      Timeout: 15
      Code:
        ZipFile: |        
          import boto3
          import logging
          import json

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          sm_client = boto3.client('sagemaker')

          #Retrieve Hyperparameters Tuning Job infomation.
          def lambda_handler(event, context):

              if ('HpoJobName' in event):
                  hpo_job_name = event['HpoJobName']

              else:
                  raise KeyError('HpoJobName key not found in function input!'+
                                ' The input received was: {}.'.format(json.dumps(event)))

              #Query boto3 API to check training status.
              response = sm_client.describe_hyper_parameter_tuning_job(HyperParameterTuningJobName = hpo_job_name)
              best_training_job = response['BestTrainingJob']
              final_hpo_objective_metric = best_training_job['FinalHyperParameterTuningJobObjectiveMetric']

              response = sm_client.describe_training_job(TrainingJobName = best_training_job['TrainingJobName'])
              logger.info("HPO Job:{} 's best training job':{}.".format(hpo_job_name, best_training_job['TrainingJobName']))
              


              return {
                  'statusCode': 200,
                  'bestTrainingJob': {
                      'trainingJobName': response['TrainingJobName'],
                      'finalHyperParameterTuningJobObjectiveMetric': final_hpo_objective_metric,
                      'modelArtifacts': response['ModelArtifacts'],
                      'hyperParameters': response['HyperParameters']
                  }
              }        
        
      Description: Query HPO Job information.

  QueryHpoJobLambdaFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      FunctionName: !Sub ${ModelName}_create_blue_green_endpoint_config
      Description: Create Blue/Green deployment Endpoint config.
      Handler: index.lambda_handler
      MemorySize: 128
      Role: !GetAtt SageMakerRole.Arn
      Runtime: python3.7
      Timeout: 15
      Code:
        ZipFile: |        
          import boto3
          import logging
          import json

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)
          sm_client = boto3.client('sagemaker')
          BLUE_VARIANT = 'blue-variant'
          GREEN_VARIANT = 'green-variant'

          #Retrieve endpoint existence and status info.
          def lambda_handler(event, context):
              logger.info(f"Input parameters: {json.dumps(event)}")

              endpoint_config_name = get_value("EndpointConfigName", event)

              dev_endpoint_name = get_value('DevEndpointName', event)
              dev_model_name = get_model_on_endpoint(dev_endpoint_name)

              prd_endpoint_name = get_value('PrdEndpointName', event)
              prd_model_name = get_model_on_endpoint(prd_endpoint_name)
              
              production_variants = get_production_variants(prd_model_name, dev_model_name)
                  

              sm_client.create_endpoint_config(
                  EndpointConfigName = endpoint_config_name,
                  ProductionVariants = production_variants
              )

              return {
                  'dev_prd_model_in_sync': (dev_model_name == prd_model_name),
                  'blue_model_name': prd_model_name,
                  'green_model_name': dev_model_name
              }

          def get_production_variant(variant_name, model_name, initial_variant_weight):
              return None if model_name == None else {
                  'VariantName': variant_name,
                  'ModelName': model_name,
                  'InitialInstanceCount': 1,
                  'InstanceType': 'ml.m5.large',
                  'InitialVariantWeight': initial_variant_weight
              }

          def get_production_variants(prd_model_name, dev_model_name):
              production_variants = []
              # always set production environment model as the first one.
              if prd_model_name:
                  production_variants.append(get_production_variant(BLUE_VARIANT, prd_model_name, 9)) # setup weight as 9 for initial blue/green setting
              if dev_model_name:
                  production_variants.append(get_production_variant(GREEN_VARIANT, dev_model_name, 1))
              return production_variants  

          def get_value(key, event):
              if (key in event):
                  return event[key]
              else:
                  raise KeyError(f'{key} key not found in function input!'+
                                f' The input received was: {json.dumps(event)}.')

          def get_model_on_endpoint(endpoint_name):
              response = sm_client.list_endpoints(NameContains = endpoint_name)
              if len(response['Endpoints']) == 0:
                  model_name = None
              else:
                  response = sm_client.describe_endpoint(EndpointName = endpoint_name)
                  endpoint_config_name = response['EndpointConfigName']
                  endpoint_config = sm_client.describe_endpoint_config(EndpointConfigName = endpoint_config_name)
                  model_name = endpoint_config['ProductionVariants'][0]['ModelName']
              return model_name

Outputs:        
  S3Bucket:
    Value: !Ref "S3Bucket"
  SageMakerRole:
    Value: !GetAtt "SageMakerRole.Arn"
  StepFunctionsWorkflowExecutionRole:
    Value: !GetAtt "StepFunctionsWorkflowExecutionRole.Arn"