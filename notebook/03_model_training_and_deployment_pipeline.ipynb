{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Deployment Pipeline\n",
    "\n",
    "The pipeline is aiming to meet below needs:\n",
    "* Data source change to trigger model retraining and deployment\n",
    "* Model training code change to trigger model retraining and deployment\n",
    "* Define a process to evaluate trained model and promotion to production environment\n",
    "\n",
    "To achieve the needs, we design the pipeline with AWS services:\n",
    "* Step Functions with [Step Functions Data Science SDK v2.0.0rc1](https://aws-step-functions-data-science-sdk.readthedocs.io/en/v2.0.0rc1/) to orchestrate model training and deployment in Amazon SageMaker platform.\n",
    "* AWS CodePipeline to define the high-level orchestration from source code and data source changes triggering model training & deployment on Dev and Production environments\n",
    "* AWS CodeBuild to process model training and deployment workflow creation and data source update.\n",
    "* AWS Lambda to process basic functions in model training / deployment\n",
    "* AWS Simple Notification Service to process notification.\n",
    "* AWS CloudFormation to create the demo ML pipeline stack.\n",
    "\n",
    "Below is the design diagram:\n",
    "\n",
    "![ML Pipeline Design](./images/ml_pipeline_design.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline Demo\n",
    "\n",
    "We demo how to trigger source code and data source change, which will trigger ML Pipeline build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipeline.ml_pipeline_dependencies import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Data Source Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download source file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://sagemaker-sample-data-us-west-2.s3-us-west-2.amazonaws.com/autopilot/direct_marketing/bank-additional.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "with zipfile.ZipFile(\"./bank-additional.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload data source to target S3 location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = boto3.client('ssm')\n",
    "response = ssm.get_parameter(Name = \"/ml_pipeline/pipeline_artifact_s3_bucket_name\")\n",
    "pipeline_artifact_bucket_name = response['Parameter']['Value']\n",
    "# model name must match with ml pipeline stack parameter - ModelName\n",
    "model_name = \"directmarketing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source_file = \"./bank-additional/bank-additional-full.csv\"\n",
    "\n",
    "target_s3_uri = f's3://${pipeline_artifact_bucket_name}/{model_name}'\n",
    "    \n",
    "sagemaker.s3.S3Uploader.upload(\n",
    "    data_source_file, \n",
    "    target_s3_uri, \n",
    "    sagemaker_session = sagemaker_session)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_pipeline_name = model_name\n",
    "display_codepipeline_advice(code_pipeline_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit Source Code Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please click 'Save' button to persist the notebook changes and we shall push the changes to repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once the changes are saved, run this cell to trigger ML pipeline\n",
    "!git add 03_model_training_and_deployment_pipeline.ipynb\n",
    "!git commit -m \"I push code change to trigger ML Pipeline.\"\n",
    "!git push"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation on Dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We shall download 'test.csv' file from processing output and use it to evaluate Dev Model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm = boto3.client('ssm')\n",
    "response = ssm.get_parameter(Name = \"/ml_pipeline/model_training_s3_bucket_name\")\n",
    "model_training_bucket_name = response['Parameter']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker.s3.S3Downloader().download(f's3://{model_training_bucket_name}/preprocessing/output/test/test.csv', './data')\n",
    "test_data = pd.read_csv('./data/test.csv')\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import CSVSerializer\n",
    "\n",
    "dev_endpoint_name = \"direct-marketing-endpoint-dev\"\n",
    "dev_predictor = Predictor(dev_endpoint_name, \n",
    "                      sagemaker_session = sagemaker_session, \n",
    "                      serializer = CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(predictor, data, rows=500):\n",
    "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
    "    predictions = ''\n",
    "    for array in split_array:\n",
    "        predictions = ','.join([predictions, predictor.predict(array).decode('utf-8')])\n",
    "\n",
    "    return np.fromstring(predictions[1:], sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(dev_predictor, test_data.drop(['y_no', 'y_yes'], axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(index=test_data['y_yes'], columns=np.round(predictions), rownames=['actuals'], colnames=['predictions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Production Variants Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate production endpoint performance against `blue` and `green` variants.\n",
    "* `blue` - it doesn't exist if prodcution endpoint has not been deployed before; or, it will be the production existing endpoint's model.\n",
    "* `green` - it's from dev endpoint, which is the release candidate model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BLUE_VARIANT_NAME = 'blue-variant'\n",
    "GREEN_VARIANT_NAME = 'green-variant'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proceed if 2 variants are deployed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_endpoint_name = \"direct-marketing-endpoint-prd\"\n",
    "\n",
    "endpoint_response = sm.describe_endpoint(\n",
    "    EndpointName = prod_endpoint_name\n",
    ")\n",
    "variant_names = [ variant['VariantName'] for variant in endpoint_response['ProductionVariants'] ]\n",
    "variant_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate variants' performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_predictor = Predictor(prod_endpoint_name, \n",
    "                      sagemaker_session = sagemaker_session, \n",
    "                      serializer = CSVSerializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(prod_predictor, test_data.drop(['y_no', 'y_yes'], axis=1).to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cw = boto3.Session().client(\"cloudwatch\")\n",
    "\n",
    "def get_invocation_metrics_for_endpoint_variant(endpoint_name,\n",
    "                                                variant_name,\n",
    "                                                start_time,\n",
    "                                                end_time):\n",
    "    metrics = cw.get_metric_statistics(\n",
    "        Namespace=\"AWS/SageMaker\",\n",
    "        MetricName=\"Invocations\",\n",
    "        StartTime=start_time,\n",
    "        EndTime=end_time,\n",
    "        Period=60,\n",
    "        Statistics=[\"Sum\"],\n",
    "        Dimensions=[\n",
    "            {\n",
    "                \"Name\": \"EndpointName\",\n",
    "                \"Value\": endpoint_name\n",
    "            },\n",
    "            {\n",
    "                \"Name\": \"VariantName\",\n",
    "                \"Value\": variant_name\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return pd.DataFrame(metrics[\"Datapoints\"])\\\n",
    "            .sort_values(\"Timestamp\")\\\n",
    "            .set_index(\"Timestamp\")\\\n",
    "            .drop(\"Unit\", axis=1)\\\n",
    "            .rename(columns={\"Sum\": variant_name})\n",
    "\n",
    "def plot_endpoint_metrics(endpoint_name, variant_names, start_time=None):\n",
    "    start_time = start_time or datetime.now() - timedelta(minutes=30)\n",
    "    end_time = datetime.now()\n",
    "    metrics_variant1 = get_invocation_metrics_for_endpoint_variant(endpoint_name, variant_names[0], start_time, end_time)\n",
    "    metrics_variants = metrics_variant1\n",
    "    if len(variant_names) > 1:\n",
    "        metrics_variant2 = get_invocation_metrics_for_endpoint_variant(endpoint_name, variant_names[1], start_time, end_time)\n",
    "        metrics_variants = metrics_variant1.join(metrics_variant2, how=\"outer\")\n",
    "    metrics_variants.plot()\n",
    "    return metrics_variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(30) #let metrics catch up\n",
    "plot_endpoint_metrics(prod_endpoint_name, variant_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More Detail on Variant Evaluation\n",
    "\n",
    "Please refer to SageMaker example notebook - [a_b_testing.ipynb](https://github.com/aws/amazon-sagemaker-examples/blob/master/sagemaker_endpoints/a_b_testing/a_b_testing.ipynb) for more detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
